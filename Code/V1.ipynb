{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ef5ba4",
   "metadata": {},
   "source": [
    "# \"Stati emozionali alla guida\" (\"Emotinal states while driving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e638bd2",
   "metadata": {},
   "source": [
    "## Parte 1 - manipolazione dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b310a",
   "metadata": {},
   "source": [
    "Questo codice importa diverse librerie e moduli comunemente utilizzati per la manipolazione dei dati, l'apprendimento automatico e le attività di valutazione. Queste librerie forniscono funzionalità per lavorare con file, dataframes, array, suddividere i dataset, implementare algoritmi di apprendimento automatico, calcolare l'accuratezza e ridimensionare le caratteristiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b6288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb030de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"results.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b700fd",
   "metadata": {},
   "source": [
    "Questo codice può essere utile quando bisogno di leggere più file Excel e memorizzarli come DataFrames separati per ulteriori elaborazioni o analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dddfe2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imposto il percorso\n",
    "folder_path2 = '..\\Dati\\Dati_Luigi_Nuovo'\n",
    "\n",
    "excel_files2 = glob.glob(os.path.join(folder_path2, \"*.xlsx\"))\n",
    "\n",
    "# Creo lista per i dataframes\n",
    "dfs2 = []\n",
    "\n",
    "# Creo una lista di colonna per import dei file excel, non essendoci intestazione\n",
    "column_headers = [chr(ord('A') + i) for i in range(32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71659735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`']\n"
     ]
    }
   ],
   "source": [
    "print(column_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037c2a4",
   "metadata": {},
   "source": [
    "Questo codice legge più file Excel, estrae colonne specifiche che sono quelle che mi servono, aggiunge una colonna 'File_Name' basata sul nome del file e unisce tutti i DataFrames risultanti in un singolo DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58779e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per ogni file, salvo i dati su dataframe\n",
    "for excel_file2 in excel_files2:\n",
    "    # leggo i file e specifico le colonne\n",
    "    df2 = pd.read_excel(excel_file2, header=None, names=column_headers[:pd.read_excel(excel_file2).shape[1]])\n",
    "    df2['File_Name'] = os.path.basename(excel_file2)  # Aggiungo la colonna 'File_Name' utilizzando il nome di base del file\n",
    "    \n",
    "    df2 = df2[['File_Name', 'D', 'H', 'J', 'L']] # Nome File, Time, HR, RR, HRV solo queste colonne da salvare\n",
    "\n",
    "    dfs2.append(df2)\n",
    "\n",
    "# Unisco tutti i DataFrames in un unico DataFrame\n",
    "merged_df2 = pd.concat(dfs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62bce4a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  File_Name         D   H   J     L\n",
      "0     AVL_BD_20211104G.xlsx  10:07:43  73  22   872\n",
      "1     AVL_BD_20211104G.xlsx  10:07:43  73  22   872\n",
      "2     AVL_BD_20211104G.xlsx  10:07:44  72  22   849\n",
      "3     AVL_BD_20211104G.xlsx  10:07:45  74  22   842\n",
      "4     AVL_BD_20211104G.xlsx  10:07:46  71  24  1068\n",
      "...                     ...       ...  ..  ..   ...\n",
      "5587  AVL_SN_20211103G.xlsx  18:25:41  73  15   812\n",
      "5588  AVL_SN_20211103G.xlsx  18:25:42  73  15   733\n",
      "5589  AVL_SN_20211103G.xlsx  18:25:43  74  15   760\n",
      "5590  AVL_SN_20211103G.xlsx  18:25:44  74  15   747\n",
      "5591  AVL_SN_20211103G.xlsx  18:25:45  75  15   762\n",
      "\n",
      "[105616 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7584e3",
   "metadata": {},
   "source": [
    "Lo scopo di questo codice è leggere più file Excel, aggiungere colonne aggiuntive a ciascun DataFrame e raccogliere tutti i DataFrames in una lista per ulteriori elaborazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7525a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = \"..\\Dati\\Dati_Luigi_arousal\"\n",
    "\n",
    "excel_files1 = glob.glob(os.path.join(folder_path1, \"*.xlsx\"))\n",
    "\n",
    "dfs1 = []\n",
    "\n",
    "for i, excel_file1 in enumerate(excel_files1):\n",
    "    df1 = pd.read_excel(excel_file1)\n",
    "    df1['File_Name'] = os.path.basename(excel_file1) \n",
    "    df1['Progressivo'] = i  # Aggiungo la colonna 'Progressivo' con il numero del file, magari può essere utile se si vuole studiare singolo file\n",
    "    dfs1.append(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c2f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join tutti i DataFrames\n",
    "merged_df1 = pd.concat(dfs1)\n",
    "\n",
    "merged_df1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceb2f553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time  Valance  Arousal              File_Name  Progressivo\n",
      "0       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0\n",
      "1       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0\n",
      "2       10:07:44       -1      201  AVL_BD_20211104G.xlsx            0\n",
      "3       10:07:45       -1      201  AVL_BD_20211104G.xlsx            0\n",
      "4       10:07:46       -1      201  AVL_BD_20211104G.xlsx            0\n",
      "...          ...      ...      ...                    ...          ...\n",
      "105599  18:25:41       84      116  AVL_SN_20211103G.xlsx           14\n",
      "105600  18:25:42       83      117  AVL_SN_20211103G.xlsx           14\n",
      "105601  18:25:43       82      118  AVL_SN_20211103G.xlsx           14\n",
      "105602  18:25:44       81      119  AVL_SN_20211103G.xlsx           14\n",
      "105603  18:25:45       80      120  AVL_SN_20211103G.xlsx           14\n",
      "\n",
      "[105604 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a79a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rinomino colonne per essere più parlanti\n",
    "merged_df2 = merged_df2.rename(columns={'D':'Time','H':'HR','J':'RR','L':'HRV'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b856991c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  File_Name      Time  HR  RR   HRV\n",
      "0     AVL_BD_20211104G.xlsx  10:07:43  73  22   872\n",
      "1     AVL_BD_20211104G.xlsx  10:07:43  73  22   872\n",
      "2     AVL_BD_20211104G.xlsx  10:07:44  72  22   849\n",
      "3     AVL_BD_20211104G.xlsx  10:07:45  74  22   842\n",
      "4     AVL_BD_20211104G.xlsx  10:07:46  71  24  1068\n",
      "...                     ...       ...  ..  ..   ...\n",
      "5587  AVL_SN_20211103G.xlsx  18:25:41  73  15   812\n",
      "5588  AVL_SN_20211103G.xlsx  18:25:42  73  15   733\n",
      "5589  AVL_SN_20211103G.xlsx  18:25:43  74  15   760\n",
      "5590  AVL_SN_20211103G.xlsx  18:25:44  74  15   747\n",
      "5591  AVL_SN_20211103G.xlsx  18:25:45  75  15   762\n",
      "\n",
      "[105616 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cf67a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time  Valance  Arousal              File_Name  Progressivo  HR   \n",
      "0       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73  \\\n",
      "1       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73   \n",
      "2       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73   \n",
      "3       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73   \n",
      "4       10:07:44       -1      201  AVL_BD_20211104G.xlsx            0  72   \n",
      "...          ...      ...      ...                    ...          ...  ..   \n",
      "169461  18:25:41       84      116  AVL_SN_20211103G.xlsx           14  73   \n",
      "169462  18:25:42       83      117  AVL_SN_20211103G.xlsx           14  73   \n",
      "169463  18:25:43       82      118  AVL_SN_20211103G.xlsx           14  74   \n",
      "169464  18:25:44       81      119  AVL_SN_20211103G.xlsx           14  74   \n",
      "169465  18:25:45       80      120  AVL_SN_20211103G.xlsx           14  75   \n",
      "\n",
      "        RR  HRV  \n",
      "0       22  872  \n",
      "1       22  872  \n",
      "2       22  872  \n",
      "3       22  872  \n",
      "4       22  849  \n",
      "...     ..  ...  \n",
      "169461  15  812  \n",
      "169462  15  733  \n",
      "169463  15  760  \n",
      "169464  15  747  \n",
      "169465  15  762  \n",
      "\n",
      "[169466 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# join dei due dataframe per nome file e time. Se time non esiste nel join, i dati sono inservibili e vengono scartati\n",
    "joined_df = pd.merge(merged_df1, merged_df2, on=['File_Name','Time'], how='left')\n",
    "\n",
    "print(joined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14109ad1",
   "metadata": {},
   "source": [
    "## Parte 2 - Equal Width Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f0216",
   "metadata": {},
   "source": [
    "Taglio automaticamente i dati dell'arousal in 4 bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da51c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['Arousal_Bin'] = pd.cut(joined_df['Arousal'], bins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ede524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time  Valance  Arousal              File_Name  Progressivo  HR   \n",
      "0       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73  \\\n",
      "1       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73   \n",
      "2       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73   \n",
      "3       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73   \n",
      "4       10:07:44       -1      201  AVL_BD_20211104G.xlsx            0  72   \n",
      "...          ...      ...      ...                    ...          ...  ..   \n",
      "169461  18:25:41       84      116  AVL_SN_20211103G.xlsx           14  73   \n",
      "169462  18:25:42       83      117  AVL_SN_20211103G.xlsx           14  73   \n",
      "169463  18:25:43       82      118  AVL_SN_20211103G.xlsx           14  74   \n",
      "169464  18:25:44       81      119  AVL_SN_20211103G.xlsx           14  74   \n",
      "169465  18:25:45       80      120  AVL_SN_20211103G.xlsx           14  75   \n",
      "\n",
      "        RR  HRV     Arousal_Bin  \n",
      "0       22  872  (151.0, 201.0]  \n",
      "1       22  872  (151.0, 201.0]  \n",
      "2       22  872  (151.0, 201.0]  \n",
      "3       22  872  (151.0, 201.0]  \n",
      "4       22  849  (151.0, 201.0]  \n",
      "...     ..  ...             ...  \n",
      "169461  15  812  (101.0, 151.0]  \n",
      "169462  15  733  (101.0, 151.0]  \n",
      "169463  15  760  (101.0, 151.0]  \n",
      "169464  15  747  (101.0, 151.0]  \n",
      "169465  15  762  (101.0, 151.0]  \n",
      "\n",
      "[169466 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abf1a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ogni bin [50,100) avrà un numero progressivo da 0 a 3\n",
    "bin_mapping = {bin_val: i for i, bin_val in enumerate(joined_df['Arousal_Bin'].unique())}\n",
    "\n",
    "# sort dei bin\n",
    "sorted_bins = sorted(joined_df['Arousal_Bin'].unique())\n",
    "\n",
    "# mappo ogni bin al numero\n",
    "bin_mapping = {bin_val: i for i, bin_val in enumerate(sorted_bins)}\n",
    "\n",
    "# salvo il mapping in una nuova colonna\n",
    "joined_df['Bin_Num'] = joined_df['Arousal_Bin'].map(bin_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "528a3e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time  Valance  Arousal              File_Name  Progressivo  HR   \n",
      "0       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73  \\\n",
      "1       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73   \n",
      "2       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73   \n",
      "3       10:07:43       -1      201  AVL_BD_20211104G.xlsx            0  73   \n",
      "4       10:07:44       -1      201  AVL_BD_20211104G.xlsx            0  72   \n",
      "...          ...      ...      ...                    ...          ...  ..   \n",
      "169461  18:25:41       84      116  AVL_SN_20211103G.xlsx           14  73   \n",
      "169462  18:25:42       83      117  AVL_SN_20211103G.xlsx           14  73   \n",
      "169463  18:25:43       82      118  AVL_SN_20211103G.xlsx           14  74   \n",
      "169464  18:25:44       81      119  AVL_SN_20211103G.xlsx           14  74   \n",
      "169465  18:25:45       80      120  AVL_SN_20211103G.xlsx           14  75   \n",
      "\n",
      "        RR  HRV     Arousal_Bin Bin_Num  \n",
      "0       22  872  (151.0, 201.0]       3  \n",
      "1       22  872  (151.0, 201.0]       3  \n",
      "2       22  872  (151.0, 201.0]       3  \n",
      "3       22  872  (151.0, 201.0]       3  \n",
      "4       22  849  (151.0, 201.0]       3  \n",
      "...     ..  ...             ...     ...  \n",
      "169461  15  812  (101.0, 151.0]       2  \n",
      "169462  15  733  (101.0, 151.0]       2  \n",
      "169463  15  760  (101.0, 151.0]       2  \n",
      "169464  15  747  (101.0, 151.0]       2  \n",
      "169465  15  762  (101.0, 151.0]       2  \n",
      "\n",
      "[169466 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(joined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d56f183",
   "metadata": {},
   "source": [
    "## Parte 3 - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1ab8d7",
   "metadata": {},
   "source": [
    "Scelto:\n",
    "150 alberi, parametro trovato con grid search per migliorare accuracy. 100 albero erano pochi per il problema\n",
    "30 foglie ad albero massimo\n",
    "10 livelli per ogni albero\n",
    "5 dati necessari per fare split\n",
    "2 dati minimo per foglia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20ca2eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write(\"Experiment for Random Forest\\n\")\n",
    "\n",
    "max_depth=10\n",
    "min_samples_split=5\n",
    "min_samples_leaf=2\n",
    "max_features=\"sqrt\"\n",
    "n_estimators=150\n",
    "max_leaf_nodes=30\n",
    "\n",
    "fp.write(f\"Parameters:\\n max_depth\\t{max_depth}\\n min_samples_split\\t{min_samples_split}\\n min_samples_leaf\\t{min_samples_leaf}\\n max_features\\t{max_features}\\n n_estimators\\t{n_estimators}\\n max_leaf_nodes\\t{max_leaf_nodes} \\n\")\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a5a439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\250515900.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# liste per salvare modelli e accuracies\n",
    "rf_models = []\n",
    "rf_accuracies = []\n",
    "\n",
    "for file_name in joined_df['File_Name'].unique():\n",
    "\n",
    "    file_data = joined_df[joined_df['File_Name'] == file_name]\n",
    "\n",
    "    # ottengo i dati di input e output X->y dove y è la label\n",
    "    X = file_data[['HR', 'RR', 'HRV']] \n",
    "    y = file_data['Bin_Num']\n",
    "\n",
    "    # Converto la colonna 'Time' in ora minuto e secondo\n",
    "    #X.loc[:, 'Hour'] = file_data['Time'].apply(lambda x: x.hour)\n",
    "    #X.loc[:, 'Minute'] = file_data['Time'].apply(lambda x: x.minute)\n",
    "    #X.loc[:, 'Second'] = file_data['Time'].apply(lambda x: x.second)\n",
    "\n",
    "    X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
    "    #X = X.drop_duplicates(subset = \"Timestamp\")\n",
    "    \n",
    "    # scaling dei dati da 0 a 1\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # split in training e test (70% training, 30% testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # creo modello RF\n",
    "    # rf_model = RandomForestClassifier()\n",
    "    rf_model = RandomForestClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, max_features=max_features, n_estimators=n_estimators, max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "\n",
    "    # fit modello su training\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluation modello su test\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # calcolo accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    rf_accuracies.append(accuracy)\n",
    "\n",
    "    # salvo modello\n",
    "    rf_models.append(rf_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bc2c8a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for File 1: 0.9287479406919276\n",
      "Accuracy for File 2: 0.7963752665245203\n",
      "Accuracy for File 3: 0.9948096885813149\n",
      "Accuracy for File 4: 0.9113887274840209\n",
      "Accuracy for File 5: 0.8528846153846154\n",
      "Accuracy for File 6: 0.7814003206841261\n",
      "Accuracy for File 7: 0.8906964921199797\n",
      "Accuracy for File 8: 0.8063591347406828\n",
      "Accuracy for File 9: 0.8788706739526412\n",
      "Accuracy for File 10: 0.8657543173672206\n",
      "Accuracy for File 11: 0.7956448911222781\n",
      "Accuracy for File 12: 0.9561808118081181\n",
      "Accuracy for File 13: 0.9365131578947369\n",
      "Accuracy for File 14: 0.9547991071428571\n",
      "Accuracy for File 15: 0.8768412438625205\n"
     ]
    }
   ],
   "source": [
    "for i, accuracy in enumerate(rf_accuracies):\n",
    "    print(f\"Accuracy for File {i+1}: {accuracy}\")\n",
    "    fp.write(f\"Accuracy for File {i+1}: {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5407e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max  accuracy for RF:  0.9948096885813149\n",
      "Min  accuracy for RF:  0.7814003206841261\n",
      "Mean accuracy for RF:  0.8818177592907707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Max  accuracy for RF: \",max(rf_accuracies))\n",
    "print(\"Min  accuracy for RF: \",min(rf_accuracies))\n",
    "print(\"Mean accuracy for RF: \",sum(rf_accuracies)/len(rf_accuracies))\n",
    "\n",
    "fp.write(f\"\\nMax  accuracy for RF: {max(rf_accuracies)}\")\n",
    "fp.write(f\"\\nMin  accuracy for RF: {min(rf_accuracies)}\")\n",
    "fp.write(f\"\\nMean accuracy for RF: {sum(rf_accuracies)/len(rf_accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e80bcd",
   "metadata": {},
   "source": [
    "## Parte 4 - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d1ee5",
   "metadata": {},
   "source": [
    "data are not linearly separable, kernel='linear' points to worst results\n",
    "parameter C = 500 to set a soft svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e906674a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write(\"\\nExperiment for SVM\\n\")\n",
    "C=500\n",
    "fp.write(f\"Parameters:\\n C\\t{C}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02c071e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1033400478.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_models = []\n",
    "svm_accuracies = []\n",
    "\n",
    "for file_name in joined_df['File_Name'].unique():\n",
    "    \n",
    "    file_data = joined_df[joined_df['File_Name'] == file_name]\n",
    "\n",
    "    X = file_data[['HR', 'RR', 'HRV']]  \n",
    "    y = file_data['Bin_Num']\n",
    "\n",
    "    #X.loc[:, 'Hour'] = file_data['Time'].apply(lambda x: x.hour)\n",
    "    #X.loc[:, 'Minute'] = file_data['Time'].apply(lambda x: x.minute)\n",
    "    #X.loc[:, 'Second'] = file_data['Time'].apply(lambda x: x.second)\n",
    "\n",
    "    X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
    "    #X = X.drop_duplicates(subset = \"Timestamp\")\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    #svm_model = SVC()\n",
    "    #svm_model = SVC(C=1.0, kernel='rbf', gamma='scale', shrinking=True)\n",
    "    svm_model = SVC(C=C, kernel='rbf', gamma='scale', shrinking=True, decision_function_shape='ovr', random_state=42)\n",
    "\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    svm_accuracies.append(accuracy)\n",
    "\n",
    "    svm_models.append(svm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3022242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for File 1: 0.8179571663920923\n",
      "Accuracy for File 2: 0.701137171286425\n",
      "Accuracy for File 3: 0.9388696655132641\n",
      "Accuracy for File 4: 0.7669959325973271\n",
      "Accuracy for File 5: 0.7355769230769231\n",
      "Accuracy for File 6: 0.7306253340459647\n",
      "Accuracy for File 7: 0.7147941026944585\n",
      "Accuracy for File 8: 0.7638780297107115\n",
      "Accuracy for File 9: 0.8128415300546448\n",
      "Accuracy for File 10: 0.7243401759530792\n",
      "Accuracy for File 11: 0.7548408710217756\n",
      "Accuracy for File 12: 0.7822878228782287\n",
      "Accuracy for File 13: 0.8657894736842106\n",
      "Accuracy for File 14: 0.7561383928571429\n",
      "Accuracy for File 15: 0.8162847790507365\n"
     ]
    }
   ],
   "source": [
    "for i, accuracy in enumerate(svm_accuracies):\n",
    "    print(f\"Accuracy for File {i+1}: {accuracy}\")\n",
    "    fp.write(f\"Accuracy for File {i+1}: {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8fe9429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max  accuracy per RF:  0.9388696655132641\n",
      "Min  accuracy per RF:  0.701137171286425\n",
      "Mean accuracy per RF:  0.7788238247211322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Max  accuracy per RF: \",max(svm_accuracies))\n",
    "print(\"Min  accuracy per RF: \",min(svm_accuracies))\n",
    "print(\"Mean accuracy per RF: \",sum(svm_accuracies)/len(svm_accuracies))\n",
    "\n",
    "fp.write(f\"\\nMax  accuracy for RF: {max(svm_accuracies)}\")\n",
    "fp.write(f\"\\nMin  accuracy for RF: {min(svm_accuracies)}\")\n",
    "fp.write(f\"\\nMean accuracy for RF: {sum(svm_accuracies)/len(svm_accuracies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a4718",
   "metadata": {},
   "source": [
    "# Part 5 \n",
    "\n",
    "### Part with circular array implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7657071b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write(\"Experiment for Circular Array implementation\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b0afb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
      "C:\\Users\\gaetano\\AppData\\Local\\Temp\\ipykernel_12508\\1918535006.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X.iloc[i:(i + time_steps)].values)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_models = []\n",
    "svm_accuracies = []\n",
    "\n",
    "for file_name in joined_df['File_Name'].unique():\n",
    "    \n",
    "    file_data = joined_df[joined_df['File_Name'] == file_name]\n",
    "\n",
    "    X = file_data[['HR', 'RR', 'HRV']]  \n",
    "    y = file_data['Bin_Num']\n",
    "\n",
    "    #X.loc[:, 'Hour'] = file_data['Time'].apply(lambda x: x.hour)\n",
    "    #X.loc[:, 'Minute'] = file_data['Time'].apply(lambda x: x.minute)\n",
    "    #X.loc[:, 'Second'] = file_data['Time'].apply(lambda x: x.second)\n",
    "\n",
    "    X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
    "    #X = X.drop_duplicates(subset = \"Timestamp\")\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    time_steps = 10\n",
    "    X_seq, y_seq = create_sequences(X, y, time_steps)\n",
    "\n",
    "    # Reshape X_seq to 2D because SVM doesn't accept 3D input\n",
    "    X_seq = X_seq.reshape(X_seq.shape[0], -1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.3, random_state=42)\n",
    "    \n",
    "    svm_model = SVC(C=1.0, kernel='rbf', gamma='scale', shrinking=True, decision_function_shape='ovr', random_state=42)\n",
    "    #print(f\"Shapes: X_train={X_train.shape}, y_train={y_train.shape}, X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    #print(f\"y_pred shape: {y_pred.shape}\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    svm_accuracies.append(accuracy)\n",
    "\n",
    "    svm_models.append(svm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cc0527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for File 1: 0.6160824742268042\n",
      "Accuracy for File 2: 0.472073995019566\n",
      "Accuracy for File 3: 0.6302715193529752\n",
      "Accuracy for File 4: 0.5010177377144519\n",
      "Accuracy for File 5: 0.4991979467436638\n",
      "Accuracy for File 6: 0.5251605995717344\n",
      "Accuracy for File 7: 0.40376782077393075\n",
      "Accuracy for File 8: 0.44835680751173707\n",
      "Accuracy for File 9: 0.6712266301869585\n",
      "Accuracy for File 10: 0.4523809523809524\n",
      "Accuracy for File 11: 0.5805522047982844\n",
      "Accuracy for File 12: 0.47575057736720555\n",
      "Accuracy for File 13: 0.7579848534738228\n",
      "Accuracy for File 14: 0.4074902179988821\n",
      "Accuracy for File 15: 0.507988529291274\n"
     ]
    }
   ],
   "source": [
    "for i, accuracy in enumerate(svm_accuracies):\n",
    "    print(f\"Accuracy for File {i+1}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00f0bb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max  accuracy per RF:  0.7579848534738228\n",
      "Min  accuracy per RF:  0.40376782077393075\n",
      "Mean accuracy per RF:  0.5299535244274829\n"
     ]
    }
   ],
   "source": [
    "print(\"Max  accuracy per RF: \",max(svm_accuracies))\n",
    "print(\"Min  accuracy per RF: \",min(svm_accuracies))\n",
    "print(\"Mean accuracy per RF: \",sum(svm_accuracies)/len(svm_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b5fbd",
   "metadata": {},
   "source": [
    "# Part 6\n",
    "\n",
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee0e3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write(\"\\nGrid Search:\")\n",
    "C_values = [0.1, 1, 10, 20,100,1000]\n",
    "time_steps_values = [1,5,10,20,50]\n",
    "fp.write(f\"\\nParameters:\\nC_Values=\\t{C_values}\\ntime_steps_values=\\t{time_steps_values}\\n\")\n",
    "fp.write(\"Results:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72cd8653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'time_steps': 1} 0.6450206473037841\n",
      "{'C': 0.1, 'time_steps': 5} 0.6503825603742721\n",
      "{'C': 0.1, 'time_steps': 10} 0.6580756299762686\n",
      "{'C': 0.1, 'time_steps': 20} 0.6678221920240468\n",
      "{'C': 0.1, 'time_steps': 50} 0.6777818471678769\n",
      "{'C': 0.1, 'time_steps': 100} 0.6953480548975433\n",
      "{'C': 1, 'time_steps': 1} 0.6954786356846971\n",
      "{'C': 1, 'time_steps': 5} 0.7024879889280181\n",
      "{'C': 1, 'time_steps': 10} 0.7111373486050161\n",
      "{'C': 1, 'time_steps': 20} 0.7257872619200472\n",
      "{'C': 1, 'time_steps': 50} 0.7593372484426203\n",
      "{'C': 1, 'time_steps': 100} 0.8023622286073772\n",
      "{'C': 10, 'time_steps': 50} 0.8351246640250714\n",
      "{'C': 10, 'time_steps': 100} 0.9044091618676444\n",
      "{'C': 20, 'time_steps': 100} 0.9282312098389519\n",
      "{'C': 50, 'time_steps': 100} 0.954498340233825\n",
      "{'C': 100, 'time_steps': 100} 0.9654982416462282\n",
      "{'C': 500, 'time_steps': 100} 0.975413353825979\n",
      "{'C': 1000, 'time_steps': 100} 0.9764304532622989\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X.iloc[i:(i + time_steps)].values)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the parameter grid\n",
    "C_values = [0.1, 1, 10, 20,50,100,500,1000]\n",
    "time_steps_values = [1,5,10,20,50,100]\n",
    "#time_steps_values = [5, 10, 15, 20, 25, 30]\n",
    "\n",
    "best_accuracy = -1\n",
    "best_params = {'C': None, 'time_steps': None}\n",
    "best_accuracies = []\n",
    "\n",
    "for C in C_values:\n",
    "    for time_steps in time_steps_values:\n",
    "        svm_accuracies = []\n",
    "        \n",
    "        for file_name in joined_df['File_Name'].unique():\n",
    "            file_data = joined_df[joined_df['File_Name'] == file_name]\n",
    "            X = file_data[['HR', 'RR', 'HRV']].copy()\n",
    "            y = file_data['Bin_Num'].copy()\n",
    "            X.loc[:, 'Timestamp'] = file_data['Time'].apply(lambda x: x.hour) * 3600 + file_data['Time'].apply(lambda x: x.minute) * 60 + file_data['Time'].apply(lambda x: x.second)\n",
    "            \n",
    "            X_seq, y_seq = create_sequences(X, y, time_steps)\n",
    "            X_seq = X_seq.reshape(X_seq.shape[0], -1)\n",
    "            \n",
    "            scaler = MinMaxScaler()\n",
    "            X_scaled = scaler.fit_transform(X_seq)\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_seq, test_size=0.3, random_state=42)\n",
    "            \n",
    "            svm_model = SVC(C=C, kernel='rbf', gamma='scale', shrinking=True, decision_function_shape='ovr', random_state=42)\n",
    "            svm_model.fit(X_train, y_train)\n",
    "            y_pred = svm_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            svm_accuracies.append(accuracy)\n",
    "        \n",
    "        mean_accuracy = np.mean(svm_accuracies)\n",
    "        fp.write(f\"\\nFor C {C} and time_steps {time_steps} the mean_accuracy is {mean_accuracy}\")\n",
    "        \n",
    "        # Update the best params if current configuration has better accuracy\n",
    "        if mean_accuracy > best_accuracy:\n",
    "            best_accuracies = svm_accuracies.copy()\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_params['C'] = C\n",
    "            best_params['time_steps'] = time_steps\n",
    "            print(best_params, mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94bc658d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 1000, 'time_steps': 100}\n",
      "[0.9666388657214345, 0.9112787356321839, 0.9988262910798122, 0.9756740914419695, 0.9702265372168285, 0.9804454101032047, 0.9850283944243676, 0.9831888626214867, 0.989843028624192, 0.9753208292201382, 0.9589123867069487, 0.990177736202058, 0.9787375415282392, 0.9937570942111237, 0.9884009942004971]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \", best_params)\n",
    "print(best_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f5760d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for File 1: 0.9666388657214345\n",
      "Accuracy for File 2: 0.9112787356321839\n",
      "Accuracy for File 3: 0.9988262910798122\n",
      "Accuracy for File 4: 0.9756740914419695\n",
      "Accuracy for File 5: 0.9702265372168285\n",
      "Accuracy for File 6: 0.9804454101032047\n",
      "Accuracy for File 7: 0.9850283944243676\n",
      "Accuracy for File 8: 0.9831888626214867\n",
      "Accuracy for File 9: 0.989843028624192\n",
      "Accuracy for File 10: 0.9753208292201382\n",
      "Accuracy for File 11: 0.9589123867069487\n",
      "Accuracy for File 12: 0.990177736202058\n",
      "Accuracy for File 13: 0.9787375415282392\n",
      "Accuracy for File 14: 0.9937570942111237\n",
      "Accuracy for File 15: 0.9884009942004971\n"
     ]
    }
   ],
   "source": [
    "fp.write(\"\\n\\nConclusion of Grid Search.\")\n",
    "fp.write(f\"\\n\\nBest parameters are {best_params} and corresponding accuracies are:\")\n",
    "for i, accuracy in enumerate(best_accuracies):\n",
    "    print(f\"Accuracy for File {i+1}: {accuracy}\")\n",
    "    fp.write(f\"\\nAccuracy for File {i+1}: {accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e492ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b67563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
